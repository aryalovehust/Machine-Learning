{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[337.   118.     4.   ...   9.65   1.     0.92]\n",
      " [324.   107.     4.   ...   8.87   1.     0.76]\n",
      " [316.   104.     3.   ...   8.     1.     0.72]\n",
      " ...\n",
      " [330.   116.     4.   ...   9.45   1.     0.91]\n",
      " [312.   103.     3.   ...   8.78   0.     0.67]\n",
      " [333.   117.     4.   ...   9.66   1.     0.95]]\n",
      "[[0.94       0.92857143 4.         ... 9.65       1.         0.92      ]\n",
      " [0.68       0.53571429 4.         ... 8.87       1.         0.76      ]\n",
      " [0.52       0.42857143 3.         ... 8.         1.         0.72      ]\n",
      " ...\n",
      " [0.8        0.85714286 4.         ... 9.45       1.         0.91      ]\n",
      " [0.44       0.39285714 3.         ... 8.78       0.         0.67      ]\n",
      " [0.86       0.89285714 4.         ... 9.66       1.         0.95      ]]\n"
     ]
    }
   ],
   "source": [
    "# To support both python 2 and python 3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "import numpy as np \n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "### Get data from CSV file\n",
    "data = pd.read_csv(\"data/Admission_Predict.csv\")\n",
    "arr = data.to_numpy()\n",
    "arr2 = arr[:,1:].T\n",
    "print(arr2.T)\n",
    "### Normalise data\n",
    "arr2[0] = (arr2[0] - arr2[0].min())/(arr2[0].ptp())\n",
    "arr2[1] = (arr2[1] - arr2[1].min())/(arr2[1].ptp())\n",
    "arr2 = arr2.T\n",
    "print(arr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_data = arr2.T[:, np.random.permutation(arr2.T.shape[1])].T ### Shuffle data\n",
    "training_data = shuffled_data[0:300] ### Get data used for training\n",
    "testing_data = shuffled_data[300:]   ### Get data used for testing\n",
    "\n",
    "training_input = training_data[:,:-1]   ### Input training data\n",
    "training_output = training_data[:,-1:]   ### Output training data\n",
    "testing_input = testing_data[:,:-1]\n",
    "testing_output = testing_data[:,-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear_Regression():\n",
    "    def __init__(self,x,w,y,learning_rate = 0.0001):\n",
    "        self.X = x\n",
    "        self.y = y\n",
    "        self.w = w\n",
    "        self.learning_rate = learning_rate\n",
    "        self.N = len(self.y)\n",
    "    def loss(self):\n",
    "        sum = float(0)\n",
    "        sum = np.linalg.norm((self.X .dot(self.w) - self.y))\n",
    "        return sum**2/(2*self.N)\n",
    "    def grad(self):\n",
    "        return (self.X.T .dot(self.X .dot(self.w) - self.y)) / self.N\n",
    "    def grad_Descent(self):\n",
    "        it = float(0)\n",
    "        lst = list()\n",
    "        while it < 100000:\n",
    "            if self.loss() < 1e-3:\n",
    "                break\n",
    "            lst.append(self.loss())\n",
    "            self.w = self.w - self.learning_rate*self.grad()\n",
    "            it = it + 1\n",
    "        return lst,it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector W after training: \n",
      "[[0.0537784 ]\n",
      " [0.04777971]\n",
      " [0.02616842]\n",
      " [0.00720882]\n",
      " [0.02957685]\n",
      " [0.05034263]\n",
      " [0.04615619]]\n",
      "Loss: 0.00266265 after 100000 iterations \n",
      "Loss got by tester: 0.00187393\n",
      "Solution found by scikit-learn  :  [[ 0.15322558  0.13341891  0.01146322 -0.00102859  0.02974777  0.04835522\n",
      "   0.02829687]]\n",
      "Loss: 0.00233921\n"
     ]
    }
   ],
   "source": [
    "w = np.zeros((7,1))\n",
    "trainer = Linear_Regression(training_input,w,training_output,0.0001)\n",
    "lst,it = trainer.grad_Descent()\n",
    "print(\"vector W after training: \")\n",
    "print(trainer.w)\n",
    "print(\"Loss: %.8f after %.0f iterations \" %(trainer.loss(),it))\n",
    "\n",
    "tester = Linear_Regression(testing_input, trainer.w, testing_output)\n",
    "print(\"Loss got by tester: %.8f\" %(tester.loss()))\n",
    "\n",
    "from sklearn import datasets, linear_model\n",
    "regr = linear_model.LinearRegression(fit_intercept=False) # fit_intercept = False for calculating the bias\n",
    "regr.fit(training_input, training_output)\n",
    "\n",
    "# Compare two results\n",
    "print( 'Solution found by scikit-learn  : ', regr.coef_ )\n",
    "train = Linear_Regression(training_input,regr.coef_.T,training_output)\n",
    "print(\"Loss: %.8f\" %(train.loss()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
