{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.   , 124.   ,  80.   , ...,   0.305,  26.   ,   0.   ],\n",
       "       [  3.   , 158.   ,  70.   , ...,   0.344,  35.   ,   1.   ],\n",
       "       [  5.   ,  95.   ,  72.   , ...,   0.37 ,  27.   ,   0.   ],\n",
       "       ...,\n",
       "       [  3.   , 113.   ,  50.   , ...,   0.626,  25.   ,   0.   ],\n",
       "       [  0.   , 137.   ,  70.   , ...,   0.17 ,  22.   ,   0.   ],\n",
       "       [  0.   , 141.   ,   0.   , ...,   0.205,  29.   ,   1.   ]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "csv = pd.read_csv(\"data/PID.csv\",header= None)\n",
    "data = csv.to_numpy()\n",
    "shuffled_data = data.T[:, np.random.permutation(data.T.shape[1])].T ### Shuffle data\n",
    "shuffled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = shuffled_data.shape[0]\n",
    "i = int(0.7*r)\n",
    "training_data = np.array(shuffled_data[:i,:], dtype = np.float128)\n",
    "testing_data = np.array(shuffled_data[i:,:], dtype = np.float128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thêm thư viện\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Hàm sigmoid\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "# Đạo hàm hàm sigmoid\n",
    "def sigmoid_derivative(x):\n",
    "    return x*(1-x)\n",
    "# Lớp neural network\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, layers, alpha=0.005):\n",
    "        #Mô hình layer ví dụ [2,2,1]\n",
    "        self.layers = layers\n",
    "        # Hệ số learning rate\n",
    "        self.alpha = alpha\n",
    "        # Tham số W, b\n",
    "        self.W = []\n",
    "        self.b = []\n",
    "        # Khởi tạo các tham số ở mỗi layer\n",
    "        for i in range(0, len(layers)-1):\n",
    "            w_ = np.random.randn(layers[i], layers[i+1])\n",
    "            b_ = np.zeros((layers[i+1], 1))\n",
    "            self.W.append(w_/layers[i])\n",
    "            self.b.append(b_)\n",
    "    # Tóm tắt mô hình neural network\n",
    "    def __repr__(self):\n",
    "        return \"Neural network [{}]\".format(\"-\".join(str(l) for l in self.layers))\n",
    "    # Train mô hình với dữ liệu\n",
    "    def out(self, X):\n",
    "        out = X[:,:-1]\n",
    "        for i in range(0, len(self.layers) - 1):\n",
    "            out = sigmoid(np.dot(out, self.W[i]) + (self.b[i].T))\n",
    "        return out\n",
    "    def calculate_loss(self,X):\n",
    "        predict = self.out(X)\n",
    "        label = np.array(X[:,-1], dtype = np.float128)\n",
    "        return -(np.sum(label*np.log(predict) + (1-label)*np.log(1-predict)))\n",
    "    def fit_partial(self,X):\n",
    "        x = np.array(X[:,:-1], dtype = np.float128)\n",
    "        y = np.array(X[:,-1], dtype = np.float128)\n",
    "        count = 0\n",
    "        # quá trình feedforward\n",
    "        while self.calculate_loss(X) > 10**-3 :\n",
    "            A = [x]\n",
    "            out = A[-1]\n",
    "            for i in range(0, len(self.layers) - 1):\n",
    "                out = sigmoid(np.dot(out, self.W[i]) + (self.b[i].T))\n",
    "                A.append(out)\n",
    "            # quá trình backpropagation\n",
    "            y = y.reshape(-1, 1)\n",
    "            dA = [-(y/A[-1] - (1-y)/(1-A[-1]))]\n",
    "            dW = []\n",
    "            db = []\n",
    "            for i in reversed(range(0, len(self.layers)-1)):\n",
    "                dw_ = np.dot((A[i]).T, dA[-1] * sigmoid_derivative(A[i+1]))\n",
    "                db_ = (np.sum(dA[-1] * sigmoid_derivative(A[i+1]), 0)).reshape(-1,1)\n",
    "                dA_ = np.dot(dA[-1] * sigmoid_derivative(A[i+1]), self.W[i].T)\n",
    "                dW.append(dw_)\n",
    "                db.append(db_)\n",
    "                dA.append(dA_)\n",
    "            # Đảo ngược dW, db\n",
    "            dW = dW[::-1]\n",
    "            db = db[::-1]\n",
    "            # Gradient descent\n",
    "            for i in range(0, len(self.layers)-1):\n",
    "                self.W[i] = self.W[i] - self.alpha * dW[i]/X.shape[0]\n",
    "                self.b[i] = self.b[i] - self.alpha * db[i]/X.shape[0]\n",
    "            count = count + 1\n",
    "            if count > 1000 :\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = NeuralNetwork([8,5,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.fit_partial(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "186088.82692925823513"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.calculate_loss(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.4168446 , -0.01230711, -0.07912232,  0.04685681,  0.07609624],\n",
       "        [-0.20182972, -0.25013562, -3.80699666,  0.19466943, -1.91126344],\n",
       "        [ 0.03112794, -0.21807764, -0.54425086,  0.10713968, -1.02813508],\n",
       "        [ 0.31406417,  0.0455551 , -0.1203092 , -0.13244833, -0.5212527 ],\n",
       "        [-0.224492  , -0.15786027, -1.68969365,  0.08398449, -4.77049796],\n",
       "        [-0.2917592 , -0.05819461, -0.82695822,  0.21663625, -0.29672625],\n",
       "        [-0.14352876, -0.16248511, -0.13168416,  0.12836948,  0.15026227],\n",
       "        [-0.86570841,  0.09107907, -0.69069356,  0.06283753, -0.82235586]],\n",
       "       dtype=float128),\n",
       " array([[-1.06603368],\n",
       "        [-0.29223698],\n",
       "        [ 0.26086196],\n",
       "        [-1.24815789],\n",
       "        [ 0.71571195]], dtype=float128)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "matplotlib.use('TkAgg')\n",
    "\n",
    "\n",
    "def forward(X, W_1, H, W_2):\n",
    "    return X.dot(W_1).dot(W_2)\n",
    "\n",
    "\n",
    "def loss(Y, Y_hat):\n",
    "    return 1 / 2 * np.sum((Y - Y_hat) / Y.shape[0] * (Y - Y_hat))\n",
    "\n",
    "\n",
    "def backward(X, H, y_hat, y, learning_rate):\n",
    "    dy = (y_hat - y).reshape(1, -1)\n",
    "    dw2 = H.T.dot(dy)\n",
    "    dh = dw2.dot(dy.T)\n",
    "    dw1 = X.reshape(1, -1).T.dot(dh.T)\n",
    "    return dw2, dw1\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Initialize\n",
    "    N = 64\n",
    "    D_in = 1000\n",
    "    H = 100\n",
    "    D_out = 10\n",
    "\n",
    "    X = np.random.rand(N, D_in)\n",
    "    Y = np.random.rand(N, D_out)\n",
    "\n",
    "    # Init weights\n",
    "    W_1 = np.random.rand(D_in, H)\n",
    "    W_2 = np.random.rand(H, D_out)\n",
    "    H = np.random.rand(1, H)\n",
    "\n",
    "    # Store loss\n",
    "    l = []\n",
    "    learning_rate = 2e-12\n",
    "\n",
    "    # Using batch gradient descent\n",
    "    for i in range(50):\n",
    "        Y_hat = forward(X, W_1, H, W_2)\n",
    "        l.append(loss(Y_hat, Y))\n",
    "        for j in range(N):\n",
    "            dw2, dw1 = backward(X[j, :], H,\n",
    "                                Y_hat[j, :], Y[j, :], learning_rate)\n",
    "            W_2 -= learning_rate * dw2\n",
    "            W_1 -= learning_rate * dw1\n",
    "\n",
    "    plt.plot(l)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
